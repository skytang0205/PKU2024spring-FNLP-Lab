{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7344b209-30a4-47f6-92e4-3edd7daa473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P', 'r', 'a', 'g', 'u', 'e', '</s>'] 107259\n"
     ]
    }
   ],
   "source": [
    "with open('bpe-training-data.txt', 'r') as file:\n",
    "    # 读取文件内容\n",
    "    data = file.read()\n",
    "data = data.split()\n",
    "\n",
    "data = [list(list(word) + ['</s>']) for word in data]\n",
    "\n",
    "print(data[0],len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a257996f-00ce-4c39-ad7b-a431f8c3e6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "vocabulary = {}\n",
    "for word in data:\n",
    "    for letter in word:\n",
    "        if letter not in vocabulary:\n",
    "            vocabulary[letter] = 0\n",
    "        vocabulary[letter] += 1\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38739d5d-2359-40fa-b5fd-c1369881702f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 b y</s> 728\n",
      "200 ti m 330\n",
      "300 u t</s> 192\n",
      "400 u e</s> 145\n",
      "500 a st 113\n",
      "600 e w</s> 90\n",
      "700 tak e</s> 75\n",
      "800 ex am 65\n",
      "900 E n 56\n",
      "1000 s ay 50\n",
      "1100 c a 44\n",
      "1200 re present 41\n",
      "1300 in fl 37\n",
      "1400 necess ary</s> 34\n",
      "1500 ab ility</s> 31\n",
      "1600 st ri 29\n",
      "1700 add ed</s> 27\n",
      "1800 ag e.</s> 25\n",
      "1900 d en 24\n",
      "2000 M c 23\n",
      "2100 tr y</s> 21\n",
      "2200 m ight</s> 20\n",
      "2300 A n</s> 19\n",
      "2400 pres ent</s> 18\n",
      "2500 sion .</s> 17\n",
      "2600 H all 17\n",
      "2700 il ,</s> 16\n",
      "2800 ag ency</s> 15\n",
      "2900 represent atives</s> 14\n",
      "3000 F or 14\n",
      "3100 C .</s> 13\n",
      "3200 C i 13\n",
      "3300 ep h 12\n",
      "3400 S e 12\n",
      "3500 on es,</s> 11\n",
      "3600 9 .</s> 11\n",
      "3700 tim ate</s> 11\n",
      "3800 sof tw 10\n",
      "3900 th anks</s> 10\n",
      "4000 hel ped</s> 10\n",
      "4100 we 're</s> 9\n",
      "4200 tal k</s> 9\n",
      "4300 concer n</s> 9\n",
      "4400 col li 9\n",
      "4500 suit able</s> 8\n",
      "4600 assu me</s> 8\n",
      "4700 win ning</s> 8\n",
      "4800 commit ted</s> 8\n",
      "4900 ish es</s> 7\n",
      "5000 pa th</s> 7\n",
      "5100 Lond on,</s> 7\n",
      "5200 scor ed</s> 7\n",
      "5300 week end,</s> 7\n",
      "5400 kilom et 7\n",
      "5500 ic es.</s> 6\n",
      "5600 c ity.</s> 6\n",
      "5700 ic i 6\n",
      "5800 rup tion</s> 6\n",
      "5900 re d,</s> 6\n",
      "6000 m ass 6\n",
      "6100 ex port</s> 6\n",
      "6200 Mr s.</s> 6\n",
      "6300 oper ation.</s> 5\n",
      "6400 Ol mer 5\n",
      "6500 lik es</s> 5\n",
      "6600 ab ducted</s> 5\n",
      "6700 Mean while,</s> 5\n",
      "6800 l am 5\n",
      "6900 di alog 5\n",
      "7000 inst antly</s> 5\n",
      "7100 H L 5\n",
      "7200 Nu eva</s> 5\n",
      "7300 B ased</s> 4\n",
      "7400 psycholog ist</s> 4\n",
      "7500 P P 4\n",
      "7600 H S 4\n",
      "7700 alleg ations</s> 4\n",
      "7800 care er</s> 4\n",
      "7900 flamenc o,</s> 4\n",
      "8000 environ ment.</s> 4\n",
      "8100 A verage</s> 4\n",
      "8200 w ounded</s> 4\n",
      "8300 Vlad im 4\n",
      "8400 revol ution 4\n",
      "8500 comp ul 4\n",
      "8600 u el 4\n",
      "8700 motorcycl es,</s> 4\n",
      "8800 refri ger 3\n",
      "8900 publ ish</s> 3\n",
      "9000 phys ics</s> 3\n",
      "9100 they 're</s> 3\n",
      "9200 cir cu 3\n",
      "9300 resul ted</s> 3\n",
      "9400 Tal e 3\n",
      "9500 2 9</s> 3\n",
      "9600 civ ic</s> 3\n",
      "9700 Leonard o</s> 3\n",
      "9800 cam pus 3\n",
      "9900 gu est</s> 3\n",
      "10000 det ect</s> 3\n",
      "10100 end or 3\n",
      "10200 Goo g 3\n",
      "10300 Stoib er</s> 3\n",
      "10400 capit al.</s> 3\n",
      "10500 pris on.</s> 3\n",
      "10600 fl ed</s> 3\n",
      "10700 pro spec 3\n",
      "10800 in dign 3\n",
      "10900 anc est 3\n",
      "11000 Trov it,</s> 3\n",
      "11100 Fran k,</s> 2\n",
      "11200 Bet ter</s> 2\n",
      "11300 ol ine</s> 2\n",
      "11400 occup i 2\n",
      "11500 ar t.</s> 2\n",
      "11600 forese eable</s> 2\n",
      "11700 lingu istic</s> 2\n",
      "11800 fil ing</s> 2\n",
      "11900 en ables</s> 2\n",
      "12000 h .</s> 2\n",
      "12100 clean er</s> 2\n",
      "12200 jum ping</s> 2\n",
      "12300 ris on</s> 2\n",
      "12400 emerg ed.</s> 2\n",
      "12500 arti st.</s> 2\n",
      "12600 M el 2\n",
      "12700 enti ve</s> 2\n",
      "12800 onn a</s> 2\n",
      "12900 ad ol 2\n",
      "13000 exp anded</s> 2\n",
      "13100 semi- final</s> 2\n",
      "13200 Or wel 2\n",
      "13300 c ow 2\n",
      "13400 differ ent.</s> 2\n",
      "13500 gene tic</s> 2\n",
      "13600 foo tw 2\n",
      "13700 pict ure 2\n",
      "13800 A tt 2\n",
      "13900 nan ot 2\n",
      "14000 outskir ts</s> 2\n",
      "14100 garb age.</s> 2\n",
      "14200 ess enti 2\n",
      "14300 increas ed.</s> 2\n",
      "14400 cigar ett 2\n",
      "14500 Dec .</s> 2\n",
      "14600 Sal vad 2\n",
      "14700 distric ts</s> 2\n",
      "14800 proc es 2\n",
      "14900 l us 2\n",
      "15000 Laetic ia,</s> 2\n",
      "15100 affec ted,</s> 2\n",
      "15200 war \"</s> 2\n",
      "15300 c roc 2\n",
      "15400 Vf B</s> 2\n",
      "15500 imagin ary</s> 2\n",
      "15600 op ted</s> 2\n",
      "15700 C oo 2\n",
      "15800 S oler 2\n",
      "15900 Tro pic 2\n"
     ]
    }
   ],
   "source": [
    "encode_list=[]\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    count += 1\n",
    "    bigram_dict = {}\n",
    "    for word in data:\n",
    "        for i in range(len(word)-1):\n",
    "            if (word[i],word[i+1]) not in bigram_dict:\n",
    "                bigram_dict[(word[i],word[i+1])] = 0\n",
    "            bigram_dict[(word[i],word[i+1])] += 1\n",
    "    w1,w2 = max(bigram_dict, key=bigram_dict.get)\n",
    "    if bigram_dict[(w1,w2)]==1: break\n",
    "    if count%100 == 0:\n",
    "        print(count, w1,w2,bigram_dict[(w1,w2)])\n",
    "    encode_list.append((w1,w2))\n",
    "    k=bigram_dict[(w1,w2)]\n",
    "    vocabulary[w1] -= k\n",
    "    vocabulary[w2] -= k\n",
    "    vocabulary[w1+w2] = k\n",
    "    \n",
    "    for word in data:\n",
    "        i = 0\n",
    "        while i < len(word) - 1:\n",
    "            if word[i] == w1 and word[i+1] == w2:\n",
    "                word[i:i+2] = [w1+w2]\n",
    "            i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3ed6d4f-ea75-4b0c-9632-a6d28f760b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the type vocabulary: 16050\n",
      "Length of the training corpus: 124695\n"
     ]
    }
   ],
   "source": [
    "#token_dict = {k: v for k, v in token_dict.items() if v != 0}\n",
    "data = [letter for word in data for letter in word]\n",
    "print(\"size of the type vocabulary: {}\\nLength of the training corpus: {}\".format(len(vocabulary),len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de01e861-79c3-4d9c-8596-a7fe9645e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encode_bigram.txt', 'w') as file:\n",
    "    # 读取文件内容\n",
    "    for w1,w2 in encode_list:\n",
    "        file.write(w1+' '+w2+'\\n')\n",
    "\n",
    "\n",
    "with open('vocabulary.txt', 'w') as file:\n",
    "    # 读取文件内容\n",
    "    for w1 in vocabulary:\n",
    "        file.write(w1+' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03c140c2-f8f0-450f-ae32-02d6149f220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1385\n",
      "8010\n",
      "4796\n",
      "4200\n",
      "3926\n",
      "3766\n",
      "3634\n",
      "3477\n",
      "3392\n",
      "3340\n",
      "3261\n",
      "3189\n",
      "3140\n",
      "3105\n",
      "3049\n",
      "3017\n",
      "2988\n",
      "2946\n",
      "2917\n",
      "2898\n",
      "2878\n",
      "2861\n",
      "2838\n",
      "2820\n",
      "2811\n",
      "2795\n",
      "2775\n",
      "2744\n",
      "2727\n",
      "2706\n",
      "2693\n",
      "2674\n",
      "2663\n",
      "2646\n",
      "2634\n",
      "2609\n",
      "2602\n",
      "2593\n",
      "2579\n",
      "2574\n",
      "2570\n",
      "2560\n",
      "2552\n",
      "2538\n",
      "2526\n",
      "2515\n",
      "2508\n",
      "2502\n",
      "2497\n",
      "2488\n",
      "2485\n",
      "2478\n",
      "2461\n",
      "2428\n",
      "2420\n",
      "2418\n",
      "2416\n",
      "2414\n",
      "2410\n",
      "2403\n",
      "2403\n",
      "2398\n",
      "2391\n",
      "2388\n",
      "2385\n",
      "2380\n",
      "2375\n",
      "2362\n",
      "2350\n",
      "2327\n",
      "2324\n",
      "2319\n",
      "2313\n",
      "2311\n",
      "2308\n",
      "2301\n",
      "2298\n",
      "2293\n",
      "2291\n",
      "2285\n",
      "2278\n",
      "2270\n",
      "2261\n",
      "2258\n",
      "2255\n",
      "2252\n",
      "2249\n",
      "2248\n",
      "2245\n",
      "2243\n",
      "2241\n",
      "2238\n",
      "2234\n",
      "2230\n",
      "2221\n",
      "2216\n",
      "2208\n",
      "2206\n",
      "2196\n",
      "2192\n",
      "2189\n",
      "2180\n",
      "2174\n",
      "2173\n",
      "2171\n",
      "2168\n",
      "2166\n",
      "2166\n",
      "2165\n",
      "2165\n",
      "2164\n",
      "2164\n",
      "2164\n",
      "2164\n",
      "2162\n",
      "2161\n",
      "2160\n",
      "2158\n",
      "2157\n",
      "2156\n",
      "2155\n",
      "2155\n",
      "2153\n",
      "2152\n",
      "2151\n",
      "2144\n",
      "2142\n",
      "2140\n",
      "2138\n",
      "2134\n",
      "2134\n",
      "2127\n",
      "2127\n",
      "2126\n",
      "2121\n",
      "2121\n",
      "2117\n",
      "2117\n",
      "2117\n",
      "2116\n",
      "2115\n",
      "2115\n",
      "2113\n",
      "2112\n",
      "2105\n",
      "2103\n",
      "2101\n",
      "2101\n",
      "2097\n",
      "2096\n",
      "2096\n",
      "2095\n",
      "2094\n",
      "2094\n",
      "2094\n",
      "2094\n",
      "2093\n",
      "2093\n",
      "2092\n",
      "2092\n",
      "2092\n",
      "['William</s>', 'Whit', 'wor', 'th,</s>', 'who</s>', 'worked</s>', 'as</s>', 'a</s>', 'writer</s>', 'and</s>', 'editor</s>', 'at</s>', 'The</s>', 'New</s>', 'Yor', 'ker</s>', 'for</s>', 'fourteen</s>', 'years</s>', 'and</s>', 'then</s>', 'ser', 'ved</s>', 'as</s>', 'editor-in-', 'chief</s>', 'of</s>', 'The</s>', 'Atl', 'an', 'tic</s>', 'Mon', 'thly</s>', 'from</s>', '198', '0</s>', 'to</s>', '1999,</s>', 'died</s>', 'last</s>', 'Friday</s>', 'in</s>', 'Ar', 'k', 'ans', 'as,</s>', 'the</s>', 'state</s>', 'where</s>', 'he</s>', 'was</s>', 'bor', 'n', '.</s>', 'He</s>', 'was</s>', 'a</s>', 'brilli', 'ant</s>', 'and</s>', 'int', 'u', 'i', 'tive</s>', 'editor</s>', 'who</s>', 'could</s>', 'see</s>', 'around</s>', 'corners</s>', 'and</s>', 'beyond</s>', 'writ', 'ers', '閳', 'ワ', '拷', '</s>', 'horiz', 'ons</s>', 'and</s>', 'deep</s>', 'into</s>', 'thor', 'ny</s>', 'man', 'us', 'crip', 'ts.</s>', 'Every', 'one</s>', 'who</s>', 'worked</s>', 'with</s>', 'him</s>', 'will</s>', 'also</s>', 'tell</s>', 'you</s>', 'that</s>', 'he</s>', 'was</s>', 'a</s>', 'pr', 'ince</s>', 'of</s>', 'a</s>', 'f', 'ell', 'ow', '.</s>', 'Th', 'rough', 'out</s>', 'publishing</s>', 'you</s>', 'could</s>', 'not</s>', 'find</s>', 'anybody</s>', 'more</s>', 'bel', 'ov', 'ed.</s>', 'In</s>', 'New</s>', 'York,</s>', 'edit', 'ors</s>', 'who</s>', 'come</s>', 'from</s>', 'L', 'it', 'tle</s>', 'R', 'ock</s>', 'are</s>', 'rar', 'e,</s>', 'even</s>', 'more</s>', 'so</s>', 'ones</s>', 'who</s>', 'attended</s>', 'the</s>', 'University</s>', 'of</s>', 'Ok', 'la', 'hom', 'a</s>', 'and</s>', 'played</s>', 'tr', 'um', 'pe', 't</s>', 'in</s>', 'the</s>', 'So', 'on', 'ers', '閳', 'ワ', '拷', '</s>', 'marching</s>', 'b', 'and', '.</s>', 'Bill</s>', '(', 'as</s>', 'colleagues</s>', 'and</s>', 'friends</s>', 'called</s>', 'him', ')</s>', 'also</s>', 'had</s>', 'his</s>', 'own</s>', 'j', 'az', 'z</s>', 'or', 'ch', 'est', 'ra', '.</s>', 'He</s>', 'played</s>', 'for</s>', 'so</s>', 'many</s>', 'd', 'ances</s>', 'and</s>', 'parties</s>', 'that</s>', 'he</s>', 'covered</s>', 'his</s>', 'tu', 'ition</s>', 'and</s>', 'expenses</s>', 'and</s>', 'came</s>', 'out</s>', 'of</s>', 'college</s>', 'in</s>', 'the</s>', 'black', '.</s>', 'On', 'c', 'e,</s>', 'he</s>', 'and</s>', 'his</s>', 'friend</s>', 'from</s>', 'L', 'it', 'tle</s>', 'R', 'ock</s>', 'Central</s>', 'High</s>', 'School</s>', 'Charles</s>', 'Patrick</s>', '(P', 'at', ')</s>', 'C', 'row</s>', 'made</s>', 'a</s>', 'trip</s>', 'to</s>', 'St', '.</s>', 'Lou', 'is</s>', 'to</s>', 'see</s>', 'D', 'iz', 'zy</s>', 'G', 'ill', 'esp', 'i', 'e.</s>', 'After</s>', 'their</s>', 'third</s>', 'night</s>', 'in</s>', 'the</s>', 'front</s>', 'row', ',</s>', 'G', 'ill', 'esp', 'i', 'e</s>', 'noticed</s>', 'them,</s>', 'asked</s>', 'them</s>', 'to</s>', 'stay</s>', 'after,</s>', 'and</s>', 'got</s>', 'to</s>', 'know</s>', 'them.</s>', 'Whit', 'worth</s>', 'invited</s>', 'him</s>', 'to</s>', 'perform</s>', 'in</s>', 'L', 'it', 'tle</s>', 'R', 'ock', ';</s>', 'G', 'ill', 'esp', 'i', 'e</s>', 'accepted</s>', 'and</s>', 'st', 'ayed</s>', 'with</s>', 'him</s>', 'and</s>', 'his</s>', 'mo', 'ther.</s>', 'Later,</s>', 'G', 'ill', 'esp', 'i', 'e</s>', 'sometimes</s>', 'st', 'ayed</s>', 'in</s>', 'Whit', 'wor', 'th', '閳', 'ユ', '獨', '</s>', 'apartment</s>', 'in</s>', 'New</s>', 'Yor', 'k.</s>', 'Whit', 'wor', 'th', '閳', 'ユ', '獨', '</s>', 'love</s>', 'of</s>', 'j', 'az', 'z</s>', 'enh', 'anced</s>', 'his</s>', 'ed', 'iting</s>', 'sk', 'ills</s>', 'and</s>', 'gave</s>', 'him</s>', 'refuge</s>', 'and</s>', 'res', 'ili', 'ence</s>', 'and</s>', 'a</s>', 'different</s>', 'way</s>', 'to</s>', 'thin', 'k.</s>', 'After</s>', 'colleg', 'e,</s>', 'he</s>', 'got</s>', 'a</s>', 'job</s>', 'at</s>', 'the</s>', 'Ar', 'k', 'ans', 'as</s>', 'G', 'az', 'ett', 'e,</s>', 'where</s>', 'he</s>', 'covered</s>', 'small</s>', 'and</s>', 'large</s>', 'st', 'ories,</s>', 'including</s>', 'the</s>', 'integr', 'ation</s>', 'strug', 'gl', 'es</s>', 'of</s>', 'the</s>', 'early</s>', 'six', 'ties.</s>', 'He</s>', 'later</s>', 'said</s>', 'that</s>', 'the</s>', 'edit', 'ors</s>', 'at</s>', 'the</s>', 'G', 'az', 'et', 'te</s>', 'taught</s>', 'him</s>', 'how</s>', 'to</s>', 'write</s>', 'a</s>', 'news</s>', 'stor', 'y.</s>', 'His</s>', 'friend</s>', 'and</s>', 'G', 'az', 'et', 'te</s>', 'col', 'league</s>', 'Charles</s>', '(', 'Bud', 'd', 'y)</s>', 'Por', 'ti', 's,</s>', 'on</s>', 'his</s>', 'way</s>', 'to</s>', 'becoming</s>', 'one</s>', 'of</s>', 'the</s>', 'greatest</s>', 'American</s>', 'writers,</s>', 'went</s>', 'to</s>', 'New</s>', 'York</s>', 'and</s>', 'worked</s>', 'at</s>', 'the</s>', 'Her', 'ald</s>', 'Tri', 'bun', 'e.</s>', 'When</s>', 'the</s>', 'Tri', 'bun', 'e</s>', 'made</s>', 'Por', 'tis</s>', 'its</s>', 'London</s>', 'correspond', 'ent,</s>', 'he</s>', 'suggested</s>', 'Whit', 'worth</s>', 'as</s>', 'his</s>', 'replac', 'ement</s>', 'in</s>', 'New</s>', 'Yor', 'k.</s>', 'Whit', 'worth</s>', 'moved</s>', 'to</s>', 'the</s>', 'city,</s>', 'and</s>', 'after</s>', 'a</s>', 'few</s>', 'years</s>', 'of</s>', 'covering</s>', 'news</s>', 'and</s>', 'writing</s>', 'features</s>', 'for</s>', 'the</s>', 'Tri', 'bun', 'e</s>', 'he</s>', 'got</s>', 'job</s>', 'offers</s>', 'from</s>', 'both</s>', 'The</s>', 'New</s>', 'Yor', 'ker</s>', 'and</s>', 'the</s>', 'Times.</s>', '(', 'Following</s>', 'a</s>', 'some', 'what</s>', 'similar</s>', 'rout', 'e,</s>', 'P', 'at</s>', 'C', 'row</s>', 'also</s>', 'ended</s>', 'up</s>', 'at</s>', 'The</s>', 'New</s>', 'Yor', 'ker', '.)</s>', 'In</s>', 'that</s>', 'era,</s>', 'the</s>', 'magazine</s>', 'was</s>', 'run</s>', 'by</s>', 'William</s>', 'Sha', 'w', 'n', '.</s>', 'Like</s>', 'Whit', 'wor', 'th,</s>', 'Sha', 'w', 'n</s>', 'was</s>', 'a</s>', 'mus', 'ic', 'ian</s>', '(', 'pi', 'ano', ').</s>', 'As</s>', 'a</s>', 'magazine</s>', 'edit', 'or,</s>', 'he</s>', 'edged</s>', 'into</s>', 'm', 'ys', 'tical</s>', 'gen', 'i', 'us</s>', 'territory.</s>', 'Whit', 'worth</s>', 'ad', 'mi', 'red</s>', 'and</s>', 'loved</s>', 'Sha', 'w', 'n,</s>', 'and</s>', 'found</s>', 'him</s>', 'end', 'lessly</s>', 'fascin', 'ating.</s>', 'Out', 'side</s>', 'of</s>', 'famil', 'y,</s>', 'Sha', 'w', 'n</s>', 'was</s>', 'the</s>', 'most</s>', 'important</s>', 'person</s>', 'in</s>', 'Whit', 'wor', 'th', '閳', 'ユ', '獨', '</s>', 'life.</s>', 'For</s>', 'all</s>', 'Sha', 'w', 'n', '閳', 'ユ', '獨', '</s>', 'diff', 'id', 'ence</s>', 'and</s>', 'quiet', 'ness,</s>', 'he</s>', 'sometimes</s>', 'did</s>', 'off-', 'the-', 'w', 'all</s>', 'things.</s>', 'Whit', 'worth</s>', 'saved</s>', 'a</s>', 'few</s>', 'gal', 'ley</s>', 'pro', 'of', 's</s>', 'with</s>', 'notable</s>', 'Sha', 'w', 'n</s>', 'comments</s>', 'on</s>', 'them,</s>', 'in</s>', 'Sha', 'w', 'n', '閳', 'ユ', '獨', '</s>', 'sm', 'all,</s>', 'clear</s>', 'hand', 'writ', 'ing.</s>', 'Paul', 'ine</s>', 'Ka', 'el,</s>', 'the</s>', 'movi', 'e</s>', 'review', 'er,</s>', 'was</s>', 'writing</s>', 'like</s>', 'someone</s>', 'poss', 'essed</s>', 'in</s>', 'the</s>', 'mid-', 's', 'ev', 'enti', 'es,</s>', 'and</s>', 'Whit', 'worth</s>', 'ed', 'ited</s>', 'her.</s>', 'Sha', 'w', 'n</s>', 'saw</s>', 'all</s>', 'pro', 'of', 's.</s>', 'Once</s>', 'Ka', 'el</s>', 'wrote</s>', 'that</s>', 'a</s>', 'particular</s>', 'actress</s>', 'was</s>', 'so</s>', 'sex', 'y</s>', 'that</s>', 'she</s>', 'was</s>', 'like</s>', '[', 'un', 'print', 'able</s>', 'simil', 'e', ']', '.</s>', 'When</s>', 'the</s>', 'proof</s>', 'came</s>', 'back</s>', 'to</s>', 'Whit', 'wor', 'th,</s>', 'Sha', 'w', 'n</s>', 'had</s>', 'under', 'lined</s>', 'the</s>', 'sim', 'ile</s>', 'and</s>', 'written</s>', 'in</s>', 'the</s>', 'marg', 'in,</s>', '閳', 'ユ', '凡', 'h', 'y</s>', 'does</s>', 'she</s>', 'do</s>', 'this', '?</s>', 'Wh', 'y?</s>', 'Wh', 'y', '?', '閳', 'ワ', '拷', '</s>', 'Dec', 'ades</s>', 'later,</s>', 'Bill</s>', 'showed</s>', 'me</s>', 'that</s>', 'saved</s>', 'gal', 'ley</s>', 'page</s>', 'with</s>', 'Sha', 'w', 'n', '閳', 'ユ', '獨', '</s>', 'qu', 'er', 'y,</s>', 'and</s>', 'it</s>', 'made</s>', 'him</s>', 'l', 'aug', 'h</s>', 'all</s>', 'over</s>', 'again.</s>', 'I</s>', 'first</s>', 'knew</s>', 'about</s>', 'Whit', 'worth</s>', 'because</s>', 'of</s>', 'his</s>', 'writ', 'ing.</s>', 'The</s>', 'summer</s>', 'I</s>', 'gradu', 'ated</s>', 'from</s>', 'college</s>', '(', 'fifty-', 'one</s>', 'years</s>', 'ag', 'o', '),</s>', 'I</s>', 'read</s>', 'a</s>', 'short</s>', 'New</s>', 'Yor', 'ker</s>', 'interview</s>', 'with</s>', 'J', 'on', 'a', 'than</s>', 'W', 'inter', 's,</s>', 'the</s>', 'Oh', 'i', 'o-', 'born</s>', 'com', 'edi', 'an.</s>', 'With</s>', 'inv', 'entive</s>', 'sp', 'ell', 'ing,</s>', 'the</s>', 'piece</s>', 'captured</s>', 'how</s>', 'W', 'inter', 's</s>', 'pr', 'on', 'ounced</s>', 'words</s>', 'in</s>', 'various</s>', 'rural</s>', 'acc', 'ent', 's', '閳', 'ユ', '敎', 'ou', '</s>', 'know', ',</s>', 'gu', 'ys</s>', 'who</s>', 'talk</s>', 'la', 'h', 'k</s>', '閳', 'ユ', '獙', 's', 's,</s>', 'hold</s>', '閳', 'ユ', '獔', 'r</s>', 'mou', 'th</s>', 'la', 'h', 'k</s>', '閳', 'ユ', '獙', 's', 's.</s>', 'An</s>', 'Oh', 'i', 'o', 'an</s>', 'my', 'self,</s>', 'I</s>', 'ad', 'mi', 'red</s>', 'how</s>', 'the</s>', 'interview', 'er</s>', 'had</s>', 'got</s>', 'W', 'inter', 's</s>', 'down.</s>', 'The</s>', 'piece</s>', 'was</s>', 'in</s>', 'The</s>', 'Tal', 'k</s>', 'of</s>', 'the</s>', 'T', 'own,</s>', 'an</s>', 'un', 'signed</s>', 'department</s>', 'back</s>', 'th', 'en.</s>', 'I</s>', 'knew</s>', 'somebody</s>', 'who</s>', 'wrote</s>', 'for</s>', 'the</s>', 'department,</s>', 'and</s>', 'I</s>', 'found</s>', 'out</s>', 'who</s>', 'had</s>', 'written</s>', 'the</s>', 'piec', 'e.</s>', 'It</s>', 'made</s>', 'me</s>', 'want</s>', 'to</s>', 'write</s>', 'for</s>', 'The</s>', 'New</s>', 'Yor', 'ker', '閳', 'ユ', '攣', 'n', 'd</s>', 'even</s>', 'think</s>', 'I</s>', 'cou', 'l', 'd.</s>', 'Sha', 'w', 'n</s>', 'later</s>', 'h', 'ired</s>', 'me</s>', 'as</s>', 'a</s>', 'Tal', 'k</s>', 'repor', 'ter,</s>', 'and</s>', 'I</s>', 'read</s>', 'all</s>', 'the</s>', 'Whit', 'worth</s>', 'pieces</s>', 'in</s>', 'the</s>', 'magaz', 'ine', '閳', 'ユ', '獨', '</s>', 'libr', 'ary.</s>', 'He</s>', 'did</s>', 'profiles</s>', 'of</s>', 'Col', 'onel</s>', 'Sand', 'ers,</s>', 'the</s>', 'fri', 'ed-', 'ch', 'ick', 'en</s>', 'fig', 'ure', 'head,</s>', 'and</s>', 'Roger</s>', 'M', 'ill', 'er,</s>', 'the</s>', 'country</s>', 'sing', 'er-', 'song', 'writer,</s>', 'and</s>', 'Jo', 'e</s>', 'Frank', 'lin,</s>', 'the</s>', 'w', 'ack', 'y,</s>', 'local</s>', 'lat', 'e-', 'night</s>', 'talk', '-', 'show</s>', 'host', ',</s>', 'and</s>', 'Dav', 'e,</s>', 'the</s>', 'aut', 'o', 'grap', 'h</s>', 'h', 'ound,</s>', 'whose</s>', 'al', 'way', 's-', 'at-', 'top-', 'volume</s>', 'dialogue</s>', 'Whit', 'worth</s>', 'con', 've', 'yed</s>', 'entirely</s>', 'in</s>', 'capital</s>', 'let', 'ters.</s>', 'He</s>', 'did</s>', 'a</s>', 'for', '-', 'the', '-h', 'eck', '-of-', 'it,</s>', '閳', 'ユ', '笜', 'o</s>', 'news</s>', 'h', 'oo', 'k', '閳', 'ワ', '拷', '</s>', 'piece</s>', 'about</s>', 'a</s>', 'p', 'ig', '</s>', 'far', 'm</s>', 'in</s>', 'Pennsylvan', 'ia,</s>', 'illustrated</s>', 'with</s>', 'a</s>', 'photo</s>', '(', 'one</s>', 'of</s>', 'the</s>', 'first', '-', 'ever</s>', 'edit', 'or', 'ial</s>', 'photos</s>', 'in</s>', 'the</s>', 'magaz', 'ine', ')</s>', 'of</s>', 'a</s>', 'p', 'ig', 'let</s>', 'd', 'ressed</s>', 'in</s>', 'a</s>', 'ba', 'by</s>', 'bon', 'net</s>', 'and</s>', 're', 'clin', 'ing</s>', 'in</s>', 'some', 'bod', 'y', '閳', 'ユ', '獨', '</s>', 'arm', 's.</s>', 'He</s>', 'described</s>', 'a</s>', 'group</s>', 'of</s>', 'p', 'ig', 'lets</s>', 'hop', 'ping</s>', 'around</s>', 'for</s>', 'joy</s>', 'and</s>', 'said</s>', 'that</s>', 'if</s>', 'they', '閳', 'ユ', '獓', '</s>', 'been</s>', 'on</s>', 'a</s>', 'hard</s>', 'sur', 'face,</s>', 'their</s>', 'h', 'oo', 'ves</s>', 'would</s>', 'have</s>', 's', 'ounded</s>', '閳', 'ユ', '笓', 'ike</s>', 'a</s>', 'room', 'ful</s>', 'of</s>', 'expert</s>', 'typ', 'ist', 's', '.', '閳', 'ワ', '拷', '</s>', 'His</s>', 'many</s>', 'pieces</s>', 'have</s>', 'never</s>', 'been</s>', 'collected</s>', 'and</s>', 'published</s>', 'as</s>', 'a</s>', 'book,</s>', 'and</s>', 'they</s>', 'should</s>', 'be.</s>', 'Ev', 'ent', 'ually</s>', 'he</s>', 'accepted</s>', 'Sha', 'w', 'n', '閳', 'ユ', '獨', '</s>', 'offer</s>', 'of</s>', 'a</s>', 'full-', 'time</s>', 'ed', 'iting</s>', 'position</s>', 'and</s>', 'worked</s>', 'on</s>', 'pieces</s>', 'like</s>', 'the</s>', 'multi', 'part</s>', 'ex', 'cer', 'p', 'ts</s>', 'from</s>', 'Robert</s>', 'Car', 'o', '閳', 'ユ', '獨', '</s>', 'book</s>', '閳', 'ユ', '翻', 'he</s>', 'Power</s>', 'Bro', 'ker', ',', '閳', 'ワ', '拷', '</s>', 'about</s>', 'Robert</s>', 'Mos', 'es.</s>', 'In</s>', '197', '9,</s>', 'Whit', 'worth</s>', 'ed', 'ited</s>', 'my</s>', 'first</s>', 'signed</s>', 'repor', 'ting</s>', 'piec', 'e,</s>', 'and</s>', 'we</s>', 'became</s>', 'friend', 's.</s>', 'When</s>', 'people</s>', 'started</s>', 'wond', 'ering</s>', 'when</s>', 'Sha', 'w', 'n</s>', 'would</s>', 'reti', 're,</s>', 'Whit', 'worth</s>', 'seemed</s>', 'the</s>', 'natural</s>', 'choice</s>', 'to</s>', 'succeed</s>', 'him.</s>', 'The</s>', 'magaz', 'ine', '閳', 'ユ', '獨', '</s>', 'then</s>', 'chair', 'man,</s>', 'Peter</s>', 'F', 'le', 'is', 'ch', 'mann,</s>', 'said</s>', 'he</s>', 'would</s>', 'give</s>', 'Whit', 'worth</s>', 'the</s>', 'job', '.</s>', 'Ag', 'ain,</s>', 'he</s>', 'had</s>', 'an</s>', 'emb', 'arr', 'ass', 'ment</s>', 'of</s>', 'offer', 's.</s>', 'At</s>', 'about</s>', 'the</s>', 'same</s>', 'time,</s>', 'M', 'ort</s>', 'Z', 'uc', 'ker', 'man,</s>', 'a</s>', 'real-estate</s>', 'developer</s>', 'who</s>', 'had</s>', 'bought</s>', 'The</s>', 'Atl', 'antic', ',</s>', 'asked</s>', 'him</s>', 'to</s>', 'take</s>', 'over</s>', 'that</s>', 'magazine.</s>', 'The</s>', 'office</s>', 'politics</s>', 'were</s>', 'complic', 'at', 'ed;</s>', 'partly</s>', 'to</s>', 'avoid</s>', 'being</s>', 'used</s>', 'as</s>', 'a</s>', 'l', 'ever</s>', 'to</s>', 'force</s>', 'Sha', 'w', 'n</s>', 'out,</s>', 'Whit', 'worth</s>', 'took</s>', 'the</s>', 'Atl', 'an', 'tic</s>', 'job</s>', 'and</s>', 'moved</s>', 'to</s>', 'Bo', 'st', 'on.</s>', 'At</s>', 'The</s>', 'Atl', 'antic', ',</s>', 'he</s>', 'ed', 'ited</s>', 'a</s>', 'dozen</s>', 'of</s>', 'my</s>', 'pieces,</s>', 'or</s>', 'more.</s>', 'He</s>', 'meant</s>', 'the</s>', 'world</s>', 'to</s>', 'me.</s>', 'Other</s>', 'writers</s>', 'he</s>', 'worked</s>', 'with</s>', 'say</s>', 'the</s>', 'same.</s>', 'He</s>', 'had</s>', 'a</s>', 'manner</s>', 'of</s>', 'sus', 'pending</s>', 'himself</s>', 'att', 'enti', 'v', 'ely</s>', 'which</s>', 'brought</s>', 'out</s>', 'the</s>', 'essenti', 'al,</s>', 'best</s>', 'version</s>', 'of</s>', 'y', 'our', 'self.</s>', 'He</s>', 'was</s>', 'thin', ',</s>', 'with</s>', 'high</s>', 't', 'em', 'ples</s>', 'and</s>', 'a</s>', 'high</s>', 'fore', 'head,</s>', 'and</s>', 'a</s>', 'mis', 'chi', 'ev', 'ous,</s>', 'anticip', 'atory</s>', 'expression</s>', 'in</s>', 'his</s>', 'ey', 'es.</s>', 'After</s>', 'M', 'ort</s>', 'Z', 'uc', 'ker', 'man</s>', 'sold</s>', 'The</s>', 'Atl', 'antic', ',</s>', 'the</s>', 'new</s>', 'owner</s>', 'brought</s>', 'in</s>', 'a</s>', 'new</s>', 'edit', 'or,</s>', 'and</s>', 'Bill</s>', 'moved</s>', 'back</s>', 'to</s>', 'L', 'it', 'tle</s>', 'R', 'ock', '.</s>', 'I</s>', 'knew</s>', 'and</s>', 'liked</s>', 'his</s>', 'son,</s>', 'Mat', 't,</s>', 'who</s>', 'worked</s>', 'in</s>', 'a</s>', 'Ch', 'else', 'a</s>', 'art</s>', 'gall', 'er', 'y.</s>', 'Matt</s>', 'moved</s>', 'to</s>', 'Min', 'ne', 'ap', 'ol', 'is,</s>', 'and</s>', 'he</s>', 'passed</s>', 'away</s>', 'two</s>', 'years</s>', 'ag', 'o', ';</s>', 'B', 'ill', '閳', 'ユ', '獨', '</s>', 'wife,</s>', 'Car', 'ol', 'y', 'n,</s>', 'had</s>', 'died</s>', 'many</s>', 'years</s>', 'before.</s>', 'Bill</s>', 'ed', 'ited</s>', 'man', 'us', 'crip', 'ts</s>', 'in</s>', 'his</s>', 'semi-', 'reti', 're', 'ment</s>', 'and</s>', 'applied</s>', 'his</s>', 'intense</s>', 'dil', 'ig', 'ence</s>', 'to</s>', 'one</s>', 'un', 'wi', 'el', 'dy</s>', 'book</s>', 'after</s>', 'an', 'other', '.</s>', 'The</s>', 'pages</s>', 'p', 'iled</s>', 'up</s>', 'in</s>', 'orderly</s>', 'st', 'acks</s>', 'in</s>', 'the</s>', 'office</s>', 'in</s>', 'his</s>', 'suburban</s>', 'house.</s>', 'He</s>', 'came</s>', 'back</s>', 'to</s>', 'New</s>', 'York</s>', 'for</s>', 'a</s>', 'book</s>', 'party</s>', 'for</s>', 'one</s>', 'of</s>', 'his</s>', 'edit', 'ees,</s>', 'and</s>', 'that', '閳', 'ユ', '獨', '</s>', 'where</s>', 'I</s>', 'met</s>', 'his</s>', 'daugh', 'ter,</s>', 'K', 'ather', 'ine</s>', 'St', 'ew', 'ar', 't,</s>', 'a</s>', 'writer</s>', 'and</s>', 'editor</s>', 'who</s>', 'lives</s>', 'in</s>', 'L', 'it', 'tle</s>', 'R', 'ock</s>', 'and</s>', 'who</s>', 'took</s>', 'care</s>', 'of</s>', 'him</s>', 'during</s>', 'his</s>', 'final</s>', 'health</s>', 'problems.</s>', 'Over</s>', 'the</s>', 'years,</s>', 'I</s>', 'dro', 've</s>', 'out</s>', 'to</s>', 'visit</s>', 'him</s>', 'in</s>', 'L', 'it', 'tle</s>', 'R', 'ock</s>', 'from</s>', 'my</s>', 'house</s>', 'in</s>', 'New</s>', 'Jersey</s>', 'three</s>', 'or</s>', 'four</s>', 'times,</s>', 'and</s>', 'flew</s>', 'out</s>', 'once.</s>', 'I</s>', 'st', 'ayed</s>', 'with</s>', 'him,</s>', 'and</s>', 'we</s>', 'went</s>', 'out</s>', 'to</s>', 'Mexican</s>', 'restaur', 'ants</s>', 'and</s>', 'watched</s>', 'music</s>', 'vide', 'os</s>', 'on</s>', 'his</s>', 'wi', 'de', '-', 'screen</s>', 'TV</s>', 'and</s>', 'list', 'ened</s>', 'to</s>', 'j', 'az', 'z</s>', 'record', 'ings</s>', 'in</s>', 'his</s>', 'living</s>', 'room.</s>', 'On', 'c', 'e,</s>', 'he</s>', 'put</s>', 'on</s>', 'an</s>', 'L', 'P</s>', 'with</s>', 'a</s>', 'solo</s>', 'by</s>', 'Lou', 'is</s>', 'Ar', 'm', 'strong', '.</s>', 'When</s>', 'it</s>', 'was</s>', 'over,</s>', 'Bill</s>', 's', 'at</s>', 'for</s>', 'a</s>', 'few</s>', 'minutes,</s>', 'quiet', 'ly</s>', 'transport', 'ed,</s>', 'and</s>', 'then</s>', 'said,</s>', '閳', 'ユ', '发', 'il', 'es</s>', 'Dav', 'is</s>', 'once</s>', 'said</s>', 'that,</s>', 'before</s>', 'Lou', 'is</s>', 'Ar', 'm', 'str', 'ong,</s>', 'all</s>', 'American</s>', 'music</s>', 'was</s>', 'cor', 'n', 'y.', '閳', 'ワ', '拷', '</s>', 'The</s>', 'statement</s>', 'may</s>', 'not</s>', 'be</s>', 'strictly</s>', 'true,</s>', 'and</s>', 'Mil', 'es</s>', 'Dav', 'is</s>', 'may</s>', 'not</s>', 'have</s>', 'said</s>', 'it,</s>', 'but</s>', 'non', 'e', 'thel', 'ess</s>', 'it</s>', 'changed</s>', 'my</s>', 'percep', 'tion.</s>', 'Stephen</s>', 'F', 'ost', 'er</s>', 'and</s>', 'John</s>', 'Philip</s>', 'S', 'ous', 'a</s>', 'will</s>', 'never</s>', 'sound</s>', 'the</s>', 'same</s>', 'to</s>', 'me</s>', 'again.</s>', 'After</s>', 'one</s>', 'vis', 'it,</s>', 'I</s>', 'was</s>', 'about</s>', 'to</s>', 'leav', 'e,</s>', 'having</s>', 'gone</s>', 'out</s>', 'through</s>', 'the</s>', 'gar', 'age</s>', 'and</s>', 'put</s>', 'my</s>', 'suit', 'case</s>', 'in</s>', 'my</s>', 'car,</s>', 'which</s>', 'was</s>', 'in</s>', 'the</s>', 'driv', 'ew', 'ay.</s>', 'The</s>', 'gar', 'age</s>', 'door</s>', 'was</s>', 'open,</s>', 'and</s>', 'we</s>', 'were</s>', 'standing</s>', 'next</s>', 'to</s>', 'his</s>', 'car.</s>', 'I</s>', 'said</s>', 'good', 'by', 'e,</s>', 'and</s>', 'Bill</s>', 'said,</s>', '閳', 'ユ', '窔', '閳', 'ユ', '獡', '</s>', 'afraid</s>', 'I', '閳', 'ユ', '獟', 'l</s>', 'never</s>', 'see</s>', 'you</s>', 'again', '.', '閳', 'ワ', '拷', '</s>', 'I</s>', 'said</s>', 'he</s>', 'would</s>', 'see</s>', 'me</s>', 'again,</s>', 'and</s>', 'in</s>', 'fact</s>', 'I</s>', 'did</s>', 'return</s>', 'to</s>', 'L', 'it', 'tle</s>', 'R', 'ock</s>', 'the</s>', 'next</s>', 'year</s>', 'or</s>', 'the</s>', 'year</s>', 'af', 'ter.</s>', 'But,</s>', 'when</s>', 'he</s>', 'said</s>', 'that,</s>', 'I</s>', 'suddenly</s>', 'felt</s>', 'such</s>', 'love</s>', 'for</s>', 'him.</s>', 'You</s>', 'can</s>', 'be</s>', 'so</s>', 'close</s>', 'to</s>', 'someone</s>', 'and</s>', 'not</s>', 'really</s>', 'understand</s>', 'how</s>', 'close</s>', 'you</s>', 'ar', 'e.</s>', 'I</s>', 'have</s>', 'done</s>', 'what</s>', 'many</s>', 'e', 'ul', 'og', 'ists</s>', 'do</s>', 'and</s>', 'have</s>', 'made</s>', 'this</s>', 'too</s>', 'much</s>', 'about</s>', 'me,</s>', 'but</s>', 'the</s>', 'number</s>', 'of</s>', 'his</s>', 'admir', 'ers</s>', 'is</s>', 'legi', 'on.</s>', 'The</s>', 'fortun', 'ate</s>', 'writers</s>', 'he</s>', 'ed', 'ited</s>', 'during</s>', 'his</s>', 'career</s>', 'were</s>', 'each</s>', 'another</s>', 'aspect</s>', 'of</s>', 'him.</s>', 'I</s>', 'am</s>', 'only</s>', 'one</s>', 'of</s>', 'hundreds</s>', 'who</s>', 'loved</s>', 'B', 'ill.</s>']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_data)\n\u001b[0;32m     30\u001b[0m unk\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m test_data[i] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m token_dict:\n\u001b[0;32m     33\u001b[0m         unk\u001b[38;5;241m.\u001b[39mappend(test_data[i])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "with open('bpe-testing-article.txt', 'r') as file:\n",
    "    # 读取文件内容\n",
    "    test_data = file.read()\n",
    "\n",
    "test_data = test_data.split()\n",
    "\n",
    "test_data = [list(word) + ['</s>'] for word in test_data]\n",
    "\n",
    "print(len(test_data))\n",
    "\n",
    "test_data = [letter for word in test_data for letter in word]\n",
    "\n",
    "print(len(test_data))\n",
    "\n",
    "count = 0\n",
    "for bigram in encode_list:\n",
    "   # if len(bigram)!=2:print(bigram,count)\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print(len(test_data))\n",
    "    i = 0\n",
    "    while i < (len(test_data) - 1):\n",
    "        if(i)==len(test_data):print(len(test_data),i)\n",
    "        if test_data[i] == bigram[0] and test_data[i+1] == bigram[1]:\n",
    "            test_data[i:i+2] = [bigram[0]+bigram[1]]\n",
    "        i += 1\n",
    "\n",
    "\n",
    "\n",
    "unk=[]\n",
    "for i in range(len(test_data)):\n",
    "    if test_data[i] not in token_dict:\n",
    "        unk.append(test_data[i])\n",
    "        test_data[i]=\"<unk>\"\n",
    "\n",
    "print(\"the final length of the article: {}\\nthe token not appear in vocabulary: {}\\nsize of the unk:{}\".format(len(test_data),unk,len(unk)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0429a1-75ed-4b91-acc5-e4756b041b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([text.replace(\"</s>\",'') for text in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f4d44-c810-42ab-909d-2c3f6e3e4fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
